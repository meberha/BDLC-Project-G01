{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f7c324-bbc6-4085-b058-84eac85494e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Virtuelle Maschinen\n",
    "### Gruppe 1\n",
    "Unsere Gruppe umfasst folgende VMs:\n",
    "\n",
    "    bdlc-05 = Matthias Eberhard\n",
    "    bdlc-11 = Philippe Michel\n",
    "    bdlc-15 = Corinne Schwarzentruber\n",
    "    \n",
    "Wir haben uns beim Aufsetzen des Clusters an das Beispiel gemäss dem Unterricht orientiert. Wir umfassen ebenfalls drei virtuelle Maschienen, womit unser Datensatz von ca. 12 GB gut bearbeitet werden kann.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65747f-72f7-432b-9e13-247ee3479bfd",
   "metadata": {},
   "source": [
    "## Topologie\n",
    "Nachfolgend ist die Übersicht unserer Topologie visuell dargestellt. \n",
    "\n",
    "Es ist ersichtlich, dass von den 47 GB RAM insgesamt 44 GB den Services zugeteilt wird. Somit verfügt jeder Node über 3 GB (oder Master 4 GB) restliche RAMs, für andere Systeme (z.Bsp. Java, Jupyter).\n",
    "\n",
    "Die 20 Prozessoren wurden bei bdlc-11 und bdlc-15 vollständig dem SPARK zugeteilt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed3cdd-1463-4e13-a029-f612f8cdb87a",
   "metadata": {},
   "source": [
    "<img src=\"V10_TopologieCluster.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8fc64-6a46-475b-a113-fa8b7c9f3952",
   "metadata": {},
   "source": [
    "### HDFS und Hadoop\n",
    "http://bdlc-05.el.eee.intern:9870/\n",
    "\n",
    "Um den Datensatz über den Cluster verteilt zu speichern und dadurch auch Redundanzen zu schaffen (für Ausfallsicherung, sollte eine VM aussteigen) installieren wir HADOOP HDFS. Dies ermöglicht auch, dass nur die Berechnungen auf dem Datensatz über das Netz laufen. Und selbstverständlich, dass wir insgesamt nun 55 Prozessoren und 121 GB RAM ansteuern können. Dies erlaubt Analysen auf grösseren Datensätzen mit einer befriedigenden Responce-Time.\n",
    "\n",
    "HDFS hat eine Master/Slave Architektur, wobei unsere VM-05 der Master ist (NameNode) und die weiteren 2 VMs sind die Slaves (DataNodes). Um die Ausfallsicherheit zu gewährleisten, muss auch der NameNode duppliziert werden. Denn nur dieser weiss, welche Datenpackete auf welcher VM gespeichert ist (incl. Metadaten). Somit initialisieren wir einen SecondNameNode auf der VM-11.\n",
    "\n",
    "Wir definieren, dass wir uns auf einen Replikationsfaktor von 2 beschränken (der Default wäre 3). Da durch die Replikation die Datenmenge multipliziert wird, macht es keinen Sinn, diesen zu hoch anzusetzen. Um das Kriterium der Ausfallsicherheit zu erfüllen, muss mindestens ein Faktor von 2 gewählt werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b2d54-50ff-4586-8b10-6e449a56f42b",
   "metadata": {},
   "source": [
    "## HIVE\n",
    "HIVE wäre ein Dienst, um verteilte SQL-Queries zu starten. Da wir uns für SPARK entschieden haben, benötigen wir HIVE nicht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae6976-6077-441f-9143-220227fedd75",
   "metadata": {},
   "source": [
    "## YARN\n",
    "\n",
    "YARN ist ebenfalls ein Dienst von Hadoop, um verteilt zu berechnen. Da wir uns für SPARK entschieden haben, haben wir YARN nicht im Einsatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59e95a-0b30-42be-9e90-1f48329f895e",
   "metadata": {},
   "source": [
    "## SPARK\n",
    "\n",
    "Auch SPARK hat eine Master/Slave-Architektur. Die Verteilung der Ressourcen haben wir auf dem Bild zur Topologie aufgeführt. Wir nutzen SPARK, da diese bezüglich Performance sehr gut optimiert ist (Logik von Actions und Transformations). Auch beinhaltet es die Möglichkeit, SQL-Queries auszuführen und übernimmt die \"Map-Reduce-Arbeiten\" in dem ein SparkJobs seine Stages (also Gruppen von Tasks) über die zur Verfügung stehenden Executors auszuführen und wieder zusammenführen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2e2a2-cd6c-4937-8860-e00d05b633df",
   "metadata": {},
   "source": [
    "## GitHub mit Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c8646-7c23-410c-984e-1f6ab5317d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@@@@"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b510f5-d564-409e-8058-1e98cc416d68",
   "metadata": {},
   "source": [
    "## Zugriff auf die Services\n",
    "\n",
    "Nachfolgend sind die URL's zu den einzelnen Services. Ist die VM korrekt gestartet, können über diese Links auf die WebUI's entsprechend zugegriffen werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f8dab-3aa5-4644-9f1a-3c8c5255bb70",
   "metadata": {},
   "source": [
    "| Service/Dienst | URL|\n",
    "| ------- | -------- |\n",
    "| HDFS DataNode |  |\n",
    "| Zeile 2 | Zelle 21 |\n",
    "| Zeile 3 | Zelle 31 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e624c-2efd-45b2-99e1-98bdd999f765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
